{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Packages for classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Packages for NLP\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD # Features from bags of word are sparse.\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train: Return fitted model\n",
    "def train(classifier, X, y):\n",
    "    test_size = 0.25\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    print('Model Accuracy: {}'.format(accuracy_score(y_test, test_pred)))\n",
    "    return model\n",
    "# Test: Return probability matrix \n",
    "def test(classifier, X):\n",
    "    return classifier.predict_proba(X)\n",
    "# Cross Validation: Return accuracy score of given classifier\n",
    "def CV(X, y, classifier):\n",
    "    prob = cross_val_predict(classifier, X, y, cv=3, method='predict_proba', n_jobs=-1)\n",
    "    pred = np.unique(y)[np.argmax(prob, axis=1)]\n",
    "    print('CV Accuracy: {}'.format(accuracy_score(y, pred)))\n",
    "    return None\n",
    "def stem(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    tknzr = TweetTokenizer()\n",
    "    list_words = tknzr.tokenize(text)\n",
    "    stem_words = [stemmer.stem(w) for w in list_words if w.isdigit() == False]\n",
    "    return ' '.join(stem_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lrc93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\lrc93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Training Set\n",
    "var_train = pd.read_csv('training_variants')\n",
    "txt_train = pd.read_csv('training_text', sep='\\|\\|', engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "training = pd.merge(var_train, txt_train, on = 'ID')\n",
    "\n",
    "# Testing Set\n",
    "var_test2 = pd.read_csv('stage2_test_variants.csv')\n",
    "txt_test2 = pd.read_csv('stage2_test_text.csv',sep='\\|\\|', engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "testing2 = pd.merge(var_test2, txt_test2, on = 'ID')\n",
    "\n",
    "# Stem text\n",
    "n_train = training.shape[0]\n",
    "n_test = testing2.shape[0]\n",
    "for i in range(n_train):\n",
    "    training['Text'][i] = stem(training['Text'][i])\n",
    "for i in range(n_test):\n",
    "    testing2['Text'][i] = stem(testing2['Text'][i])\n",
    "training.to_csv('training_stemmed.csv', index = False, encoding = 'utf-8')\n",
    "testing2.to_csv('testing_stemmed.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training_stemmed.csv', encoding = 'utf-8')\n",
    "testing2 = pd.read_csv('testing_stemmed.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.641395908543923\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(analyzer=\"word\", stop_words='english', max_features = 80)\n",
    "tf_idf = tfidf.fit_transform(training['Text'])\n",
    "words = tfidf.get_feature_names() # Use the same dictionary as training features\n",
    "tfidf_test = TfidfVectorizer(analyzer=\"word\", stop_words='english', max_features = 80, vocabulary = words)\n",
    "tf_idf_test = tfidf_test.fit_transform(testing2['Text'])\n",
    "\n",
    "# Train Model\n",
    "X = tf_idf\n",
    "y = training['Class']\n",
    "model = XGBClassifier()\n",
    "model_train = train(model, X, y)\n",
    "\n",
    "# Prediction\n",
    "T = tf_idf_test\n",
    "r = test(model_train, T)\n",
    "r_ID = np.c_[testing2['ID'],r]\n",
    "submit = pd.DataFrame(r_ID, columns= ['ID','class1','class2','class3','class4','class5','class6','class7','class8','class9'])\n",
    "submit['ID'] = submit['ID'].astype(int)\n",
    "submit.head()\n",
    "submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activ',\n",
       " 'al',\n",
       " 'all',\n",
       " 'also',\n",
       " 'an',\n",
       " 'analysi',\n",
       " 'and',\n",
       " 'are',\n",
       " 'as',\n",
       " 'assay',\n",
       " 'associ',\n",
       " 'at',\n",
       " 'be',\n",
       " 'been',\n",
       " 'between',\n",
       " 'bind',\n",
       " 'both',\n",
       " 'brca',\n",
       " 'but',\n",
       " 'by',\n",
       " 'cancer',\n",
       " 'case',\n",
       " 'cell',\n",
       " 'clinic',\n",
       " 'data',\n",
       " 'differ',\n",
       " 'dna',\n",
       " 'domain',\n",
       " 'effect',\n",
       " 'egfr',\n",
       " 'et',\n",
       " 'exon',\n",
       " 'express',\n",
       " 'fig',\n",
       " 'figur',\n",
       " 'for',\n",
       " 'from',\n",
       " 'function',\n",
       " 'gene',\n",
       " 'has',\n",
       " 'have',\n",
       " 'human',\n",
       " 'identifi',\n",
       " 'in',\n",
       " 'includ',\n",
       " 'increas',\n",
       " 'indic',\n",
       " 'inhibitor',\n",
       " 'interact',\n",
       " 'is',\n",
       " 'it',\n",
       " 'kinas',\n",
       " 'level',\n",
       " 'line',\n",
       " 'may',\n",
       " 'mutant',\n",
       " 'mutat',\n",
       " 'not',\n",
       " 'observ',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'patient',\n",
       " 'phosphoryl',\n",
       " 'protein',\n",
       " 'ras',\n",
       " 'report',\n",
       " 'residu',\n",
       " 'resist',\n",
       " 'respons',\n",
       " 'result',\n",
       " 'sequenc',\n",
       " 'show',\n",
       " 'shown',\n",
       " 'signal',\n",
       " 'signific',\n",
       " 'structur',\n",
       " 'studi',\n",
       " 'suggest',\n",
       " 'tabl',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'these',\n",
       " 'this',\n",
       " 'to',\n",
       " 'tumor',\n",
       " 'two',\n",
       " 'typ',\n",
       " 'use',\n",
       " 'variant',\n",
       " 'was',\n",
       " 'we',\n",
       " 'were',\n",
       " 'which',\n",
       " 'wild',\n",
       " 'with']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
